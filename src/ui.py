"""
Gradio UI for LinguaTravel application.
Universal Compatibility Mode
"""

import gradio as gr
from typing import List, Tuple, Optional, Any
from .config import Config
from .ollama_service import OllamaService
from .whisper_service import WhisperService

class LinguaTravelUI:
    """Manages the Gradio interface for the application."""
    
    def __init__(self, ollama_service: OllamaService, whisper_service: WhisperService):
        self.ollama = ollama_service
        self.whisper = whisper_service
        self.current_language = "Spanish"
        
    def handle_text_message(
        self, 
        message: str, 
        history: List[List[Any]]
    ) -> Tuple[str, List[List[Any]]]:
        """
        Handle text message using List of Lists format (Universal compatibility).
        """
        if not message.strip():
            return "", history
        
        history = history or []
        
        # 1. ä½¿ç”¨ [User, None] æ ¼å¼åŠ å…¥ä½¿ç”¨è€…è¨Šæ¯
        # æ³¨æ„ï¼šé€™è£¡ç”¨åˆ—è¡¨ [message, ""] ä»£è¡¨ä¸€çµ„å°è©±
        history.append([message, ""])
        
        response = ""
        # ä¸²æµç”Ÿæˆå›æ‡‰
        for chunk in self.ollama.generate_response(message, self.current_language):
            response += chunk
            # æ›´æ–°æœ€å¾Œä¸€çµ„å°è©±çš„ç¬¬äºŒå€‹å…ƒç´  (AI å›æ‡‰)
            history[-1][1] = response
            yield "", history
        
        return "", history
    
    def handle_audio_message(
        self,
        audio_path: Optional[str],
        history: List[List[Any]]
    ) -> Tuple[str, List[List[Any]]]:
        """
        Handle audio message using List of Lists format.
        """
        if not audio_path:
            return "", history
            
        history = history or []
        
        # Transcribe
        transcription = self.whisper.transcribe_audio_with_feedback(audio_path)
        
        # ç³»çµ±è¨Šæ¯ï¼š[None, è¨Šæ¯] ä»£è¡¨ç³»çµ±æç¤º
        history.append([None, f"ğŸ¤ **Voice Input Detected**\n\n{transcription}"])
        
        result = self.whisper.transcribe_audio(audio_path)
        if result.get("text") and not result.get("error"):
            user_text = result["text"]
            
            # åŠ å…¥ä½¿ç”¨è€…è­˜åˆ¥å‡ºçš„æ–‡å­—
            history.append([user_text, ""])
            
            response = ""
            for chunk in self.ollama.generate_response(user_text, self.current_language):
                response += chunk
                history[-1][1] = response
                yield "", history
        
        return "", history
    
    def handle_quick_phrase(
        self,
        phrase_key: str,
        history: List[List[Any]]
    ) -> List[List[Any]]:
        """
        Handle quick phrase using List of Lists format.
        """
        history = history or []
        
        phrase_template = Config.QUICK_PHRASES.get(phrase_key, "")
        if not phrase_template:
            return history
        
        phrase = phrase_template.replace("{language}", self.current_language)
        
        # åŠ å…¥å°è©±
        history.append([phrase, ""])
        
        response = ""
        for chunk in self.ollama.generate_response(phrase, self.current_language):
            response += chunk
            history[-1][1] = response
            yield history
        
        return history
    
    def update_language(self, language: str) -> str:
        self.current_language = language
        return f"ğŸŒ Learning language changed to: **{language}**"
    
    def clear_conversation(self) -> Tuple[List, str]:
        self.ollama.clear_history()
        return [], "ğŸ—‘ï¸ Conversation cleared!"
    
    def setup_model(self) -> str:
        if self.ollama.check_model_exists():
            return f"âœ… Model '{self.ollama.model}' is already available!"
        
        status_messages = []
        for status in self.ollama.pull_model():
            status_messages.append(status)
            yield "\n".join(status_messages)
        
        return "\n".join(status_messages) + "\n\nâœ… Model setup complete!"
    
    def create_interface(self) -> gr.Blocks:
        with gr.Blocks(title=Config.APP_TITLE) as interface:
            
            gr.Markdown(f"# {Config.APP_TITLE}")
            gr.Markdown(Config.APP_DESCRIPTION)
            
            with gr.Row():
                with gr.Column(scale=2):
                    ollama_status = gr.Markdown(self.ollama.get_status_message())
                    whisper_status = gr.Markdown(self.whisper.get_status())
                with gr.Column(scale=1):
                    language_selector = gr.Dropdown(
                        choices=Config.SUPPORTED_LANGUAGES,
                        value="Spanish",
                        label="ğŸŒ Learning Language",
                        interactive=True
                    )
                    language_status = gr.Markdown("")
            
            # ğŸ”´ é‡é»ä¿®æ­£ 1: ç§»é™¤ type="messages"ï¼Œé è¨­æ¥å— List of Lists
            chatbot = gr.Chatbot(
                label="Conversation",
                height=400,
                show_label=True
            )
            
            with gr.Row():
                with gr.Column(scale=4):
                    text_input = gr.Textbox(
                        label="Type your message",
                        placeholder="e.g., How do I say 'thank you' in Spanish?",
                        lines=1
                    )
                with gr.Column(scale=1):
                    # ğŸ”´ é‡é»ä¿®æ­£ 2: ä½¿ç”¨ sources (è¤‡æ•¸)ï¼Œé¿é–‹ source (å–®æ•¸) çš„éŒ¯èª¤
                    audio_input = gr.Audio(
                        sources=["microphone"], 
                        type="filepath",
                        label="ğŸ¤ Or speak"
                    )
            
            gr.Markdown("### ğŸš€ Quick Phrases")
            with gr.Row():
                quick_buttons = []
                for phrase_key in Config.QUICK_PHRASES.keys():
                    btn = gr.Button(phrase_key) # sizeåƒæ•¸ä¹Ÿå…ˆæ‹¿æ‰ï¼Œä¿éšªèµ·è¦‹
                    quick_buttons.append((phrase_key, btn))
            
            with gr.Row():
                clear_btn = gr.Button("ğŸ—‘ï¸ Clear Conversation", variant="secondary")
                setup_model_btn = gr.Button("ğŸ“¥ Setup Model", variant="primary")
            
            setup_output = gr.Markdown("")
            
            # Event handlers
            text_input.submit(
                self.handle_text_message,
                inputs=[text_input, chatbot],
                outputs=[text_input, chatbot]
            )
            
            audio_input.change(
                self.handle_audio_message,
                inputs=[audio_input, chatbot],
                outputs=[text_input, chatbot]
            )
            
            for phrase_key, btn in quick_buttons:
                # ä½¿ç”¨ lambda è™•ç†ç”Ÿæˆå™¨
                btn.click(
                    lambda history, pk=phrase_key: self.handle_quick_phrase(pk, history),
                    inputs=[chatbot],
                    outputs=[chatbot]
                )
            
            language_selector.change(
                self.update_language,
                inputs=[language_selector],
                outputs=[language_status]
            )
            
            clear_btn.click(
                self.clear_conversation,
                outputs=[chatbot, language_status]
            )
            
            setup_model_btn.click(
                self.setup_model,
                outputs=[setup_output]
            )
            
            gr.Markdown("""
            ---
            **Tips:**
            - ğŸ’¬ Type or speak to practice conversations
            - ğŸ¯ Use quick phrases for common scenarios
            - ğŸ¤ Use voice input to practice pronunciation
            - ğŸŒ Switch languages to learn different phrases
            """)
        
        return interface
